{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "483387d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sudo apt install python3-opencv\n",
    "import cv2\n",
    "print(cv2.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71031ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import sys\n",
    "\n",
    "# read image\n",
    "image_path = os.path.join('..', 'imgs', 'jackie.jpg')\n",
    "\n",
    "img = cv2.imread (image_path)\n",
    "\n",
    "if img is None:\n",
    "    sys.exit(\"Could not read the image.\")\n",
    "\n",
    "# write image\n",
    "cv2.imwrite(os.path.join('.', 'imgs', 'sample1_copy.jpg'), img)\n",
    "\n",
    "# This line opens a pop up window\n",
    "# visualize images\n",
    "cv2.imshow('image', img)\n",
    "cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows() simply destroys all the windows we created.\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da7a9928",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# read image\n",
    "image_path = os.path.join('..', 'data', 'sample2.jpg')\n",
    "\n",
    "img = cv2.imread (image_path)\n",
    "\n",
    "if img is None:\n",
    "    sys.exit(\"Could not read the image.\")\n",
    "\n",
    "# write image\n",
    "cv2.imwrite(os.path.join('..', 'data', 'sample1_copy.jpg'), img)\n",
    "\n",
    "# This line opens a pop up window\n",
    "# visualize images\n",
    "cv2.imshow('image', img)\n",
    "cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows() simply destroys all the windows we created.\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB)),plt.title('Original Image')\n",
    "plt.xticks([]), plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca7dd3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b2cf5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "b, g, r = img[10, 20] \n",
    "print(b, g, r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4244e8d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#img = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "# show Blue values\n",
    "cv2.imshow('image-B', img[:,:,0])\n",
    "# show Green values\n",
    "cv2.imshow('image-G', img[:,:,1])\n",
    "# show Red values\n",
    "cv2.imshow('image-R', img[:,:,2])\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "492ff93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to show in colour values\n",
    "\n",
    "b = img.copy()\n",
    "# set green and red channels to 0\n",
    "b[:, :, 1] = 0\n",
    "b[:, :, 2] = 0\n",
    "\n",
    "\n",
    "g = img.copy()\n",
    "# set blue and red channels to 0\n",
    "g[:, :, 0] = 0\n",
    "g[:, :, 2] = 0\n",
    "\n",
    "r = img.copy()\n",
    "# set blue and green channels to 0\n",
    "r[:, :, 0] = 0\n",
    "r[:, :, 1] = 0\n",
    "\n",
    "\n",
    "# RGB - Blue\n",
    "cv2.imshow('B-RGB', b)\n",
    "\n",
    "# RGB - Green\n",
    "cv2.imshow('G-RGB', g)\n",
    "\n",
    "# RGB - Red\n",
    "cv2.imshow('R-RGB', r)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e9f37c",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = os.path.join ('..', 'imgs', 'jackie.jpg')\n",
    "#image_path = os.path.join ('..', 'data', 'miguel.jpg')\n",
    "\n",
    "img = cv2.imread (image_path)\n",
    "\n",
    "if img is None:\n",
    "    sys.exit(\"Could not read the image.\")\n",
    "\n",
    "cv2.imshow('BGR image', img)\n",
    "print(img.shape)\n",
    "\n",
    "img_rgb = cv2.cvtColor (img, cv2.COLOR_BGR2RGB)\n",
    "cv2.imshow ('RGB image', img_rgb)\n",
    "print(img_rgb.shape)\n",
    "\n",
    "img_gray = cv2.cvtColor (img, cv2.COLOR_BGR2GRAY)\n",
    "cv2.imshow ('Gray image', img_gray)\n",
    "print(img_gray.shape)\n",
    "\n",
    "img_hsv = cv2.cvtColor (img, cv2.COLOR_BGR2HSV)\n",
    "cv2.imshow ('HSV image', img_hsv)\n",
    "print(img_hsv.shape)\n",
    "\n",
    "\n",
    "cv2.waitKey (0)\n",
    "cv2.destroyAllWindows ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88be12f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# read image\n",
    "image_path = os.path.join('..', 'imgs', 'jackie.jpg')\n",
    "\n",
    "img = cv2.imread (image_path)\n",
    "\n",
    "if img is None:\n",
    "    sys.exit(\"Could not read the image.\")\n",
    "\n",
    "blank = np.zeros_like(img[:,:,0])\n",
    "\n",
    "# Extract the Blue, Green, and Red channels\n",
    "b_img = cv2.merge([img[:, :, 0], blank, blank])  # Only blue\n",
    "g_img = cv2.merge([blank, img[:, :, 1], blank])  # Only green\n",
    "r_img = cv2.merge([blank, blank, img[:, :, 2]])    # Only red\n",
    "\n",
    "cv2.imshow('original', img)\n",
    "# show Blue values\n",
    "cv2.imshow('image-G', g_img)\n",
    "cv2.imshow('image_B', b_img)\n",
    "cv2.imshow('image_R', r_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "128c2874",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_yuv = cv2.cvtColor(img, cv2.COLOR_BGR2YUV)\n",
    "y, u, v = cv2.split(img_yuv)\n",
    "\n",
    "cv2.imshow('y', y)\n",
    "cv2.imshow('u', u)\n",
    "cv2.imshow('v', v)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fded0b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "flags = [i for i in dir(cv) if i.startswith('COLOR_')]\n",
    "print( flags )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e4dc80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "image_path = os.path.join('..', 'data', 'sample2.jpg')\n",
    "# read image in grey scale\n",
    "img = cv2.imread (image_path, 0)\n",
    "\n",
    "cv2.imshow('image', img)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "from matplotlib import pyplot as plt \n",
    "plt.hist(img.ravel(),256,[0,256]) \n",
    "plt.show() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad98eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# see the pixel intensities for YUV\n",
    "plt.figure().set_figwidth(15)\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.hist(y.ravel(),256,[0,256]) \n",
    "plt.subplot(1, 3, 2)\n",
    "plt.hist(u.ravel(),256,[0,256]) \n",
    "plt.subplot(1, 3, 3)\n",
    "plt.hist(v.ravel(),256,[0,256]) \n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fba5919",
   "metadata": {},
   "source": [
    "<h2><font color=#f542f2><bold>1.5 Read, Write, and Display a Video Using OpenCV (Without Sound)</bold></font></h2>\n",
    "> **what is a video?** A video is a sequence of fast moving images. The obvious question that follows is how fast are the pictures moving? The measure of how fast the images are transitioning is given by a metric called **frames per second(FPS)**.\n",
    "\n",
    "> When someone says that the video has an FPS of 40, it means that 40 images are being displayed every second. Alternatively, after every 25 milliseconds, a new frame is displayed. The other important attributes are the width and height of the frame.\n",
    "\n",
    "> In OpenCV, a video can be read either by using the feed from a camera connected to a computer or by reading a video file. The first step towards reading a video file is to create a VideoCapture object. Its argument can be either the device index or the name of the video file to be read.\n",
    "\n",
    "> **Displaying the Video:** After reading a video file, we can display the video frame by frame. A frame of a video is simply an image and we display each frame the same way we display images, i.e., we use the function `cv2.imshow()`.\n",
    "\n",
    "> As in the case of an image, we use the `cv2.waitKey()` after `cv2.imshow()` function to pause each frame in the video. In the case of an image, we pass ‘0’ to the `cv2.waitKey()` function, but for playing a video, we need to pass a number greater than ‘0’ to the `cv2.waitKey()` function. This is because ‘0’ would pause the frame in the video for an infinite amount of time and in a video we need each frame to be shown only for some finite interval of time. So, we need to pass a number greater than ‘0’ to the `cv2.waitKey()` function. This number is equal to the time in milliseconds we want each frame to be displayed.\n",
    ">\n",
    "> While reading the frames from a webcam, using `cv2.waitKey(1)` is appropriate because the display frame rate will be limited by the frame rate of the webcam even if we specify a delay of 1 ms in waitKey.\n",
    "\n",
    "> While reading frames from a video that you are processing, it may still be appropriate to set the time delay to 1 ms so that the thread is freed up to do the processing we want to do.\n",
    "\n",
    "> In rare cases, when the playback needs to be at a certain framerate, we may want the delay to be higher than 1 ms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed1dc97c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "\n",
    "# Create a VideoCapture object and read from input file\n",
    "# If the input is the camera, pass 0 instead of the video file name\n",
    "video_path = os.path.join('..', 'data', 'BR99.mp4')\n",
    "\n",
    "video_cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# Check if camera opened successfully\n",
    "if (video_cap.isOpened()== False): \n",
    "    print(\"Error opening video stream or file\")\n",
    "\n",
    "# Get video details\n",
    "fps = video_cap.get(cv2.CAP_PROP_FPS)\n",
    "ft = video_cap.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "width = int(video_cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(video_cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "while video_cap.isOpened():\n",
    "    # Reading frames of the video\n",
    "    ret, frame = video_cap.read ()\n",
    "\n",
    "    if not ret:\n",
    "        break\n",
    "        \n",
    "    cv2.imshow('frame', frame)\n",
    "    \n",
    "    # Break the loop if 'q' is pressed\n",
    "    if cv2.waitKey(int(1000 / fps)) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the VideoCapture object and close all windows\n",
    "video_cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f43b9d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fps)\n",
    "print(ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20bbf758",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "\n",
    "video_path = os.path.join('..', 'data', 'BR99.mp4')\n",
    "video_cap = cv2.VideoCapture(video_path)\n",
    "video_cap.set(cv2.CAP_PROP_POS_FRAMES, 10)\n",
    "ret, frame = video_cap.read()\n",
    "cv2.imshow('frame captured', frame)\n",
    "\n",
    "while True:\n",
    "    ch = 0xFF & cv2.waitKey(1) # Wait for a second\n",
    "    if ch == ord('q'):\n",
    "        break\n",
    "\n",
    "video_cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9132776",
   "metadata": {},
   "source": [
    "- `video_cap.read()` returns a bool (True/False). If the frame is read correctly, it will be True. So you can check for the end of the video by checking this returned value.\n",
    "\n",
    "- Sometimes, video_cap may not have initialized the capture. You can check whether it is initialized or not by the method `video_cap.isOpened()`. If it is True, OK. Otherwise open it using `video_cap.open()`.\n",
    "\n",
    "- You can also access some of the features of this video using `video_cap.get(propId)` method where propId is a number from 0 to 18. Each number denotes a property of the video (if it is applicable to that video). Full details can be seen [here](https://docs.opencv.org/4.x/d8/dfe/classcv_1_1VideoCapture.html#aa6480e6972ef4c00d74814ec841a2939). Some of these values can be modified using `video_cap.set(propId, value)`. Value is the new value you want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "425492e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 640, 3)\n",
      "(240, 320, 3)\n"
     ]
    }
   ],
   "source": [
    "# Resizing\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "# Read the image\n",
    "image_path = os.path.join('..', 'data', 'sample2.jpg')\n",
    "\n",
    "img = cv2.imread(image_path)\n",
    "\n",
    "# check for errors\n",
    "if img is None:\n",
    "    sys.exit(\"Could not read the image.\")\n",
    "\n",
    "# Printing the shape of the image (height, width, channels)\n",
    "print(img.shape)\n",
    "\n",
    "# Displaying the image\n",
    "cv2.imshow('image', img)\n",
    "\n",
    "# Resizing the image\n",
    "resized_img = cv2.resize (img, (int(img.shape[1]/2), int(img.shape[0]/2)))\n",
    "\n",
    "print(resized_img.shape)\n",
    "\n",
    "cv2.imshow('resized image', resized_img)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2f3fe50a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1280, 1920, 3)\n",
      "(450, 1100, 3)\n"
     ]
    }
   ],
   "source": [
    "# Cropping \n",
    "import os\n",
    "import cv2\n",
    "\n",
    "# Read the image\n",
    "image_path = os.path.join('..', 'data', 'fedor.jpg')\n",
    "img = cv2.imread (image_path)\n",
    "\n",
    "if img is None:\n",
    "    sys.exit(\"Could not read the image.\")\n",
    "\n",
    "# check for errors\n",
    "if img is None:\n",
    "    sys.exit(\"Could not read the image.\")\n",
    "\n",
    "# Printing the shape of the image (height, width, channels)\n",
    "print(img.shape)\n",
    "\n",
    "# Displaying the image\n",
    "cv2.imshow('image', img)\n",
    "\n",
    "# image is just a numpy array. So, to crop it we can just use slicing techniques\n",
    "cropped_img = img[600:1050, 150:1250]\n",
    "cv2.imshow('cropped image', cropped_img)\n",
    "print(cropped_img.shape)\n",
    "\n",
    "cv2.waitKey (0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42158dcb",
   "metadata": {},
   "source": [
    "<h2><font color=#f542f2><strong>1.9 Image Enhancement Techniques</strong></font></h2>\n",
    "<h3><font color=#4296f5><strong>1.9.1 Adjusting brightness and contrast</strong></font></h3>\n",
    "\n",
    "Adjusting the brightness and contrast of an image can significantly affect its visual appeal and effectiveness. It can also help to correct defects or flaws in the image and make it easier to see details. Finding the right balance of brightness and contrast is important for creating an attractive and effective image.\n",
    "\n",
    "There are several ways to adjust the brightness and contrast of an image using OpenCV and Python. One common method is to use the `cv2.addWeighted()` function, which allows you to adjust the brightness by adding a scalar value to each pixel in the image, and the contrast by scaling the pixel values.\n",
    "Here is an example of how to adjust the brightness and contrast of an image using the `cv2.addWeighted()` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a087dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
